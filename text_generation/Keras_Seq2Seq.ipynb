{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Original Post](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) <br>\n",
        "[Updated Post](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
        "\n",
        "General Case: Canonical seq-2-seq <p>\n",
        "Input and Output sequences have different lengths, and entire input sequence is required in order to start predicting the target. Requires a more advanced setup. How it works:\n",
        "-  RNN layer (or stack of) acts as an 'encoder'; processes input sequence and returns its own internal state. Note we will discard the outputs of encoder RNN, only recovering the state. This will serve as the 'context', or 'conditioning' of the decoder in the next step.\n",
        "-  Another RNN layer (or stack of) acts as the 'decoder'; it is trained to predict the next characters of the target sequence, given previous characters of the target sequence. Specifically, it is trained to turn the target sequences into the same sequences but offset by one timestep in the future, a training process called 'teacher forcing' in this context. <br>\n",
        "Importantly, the decoder uses as an initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate. Effectively, the decoder learns to generate targets[t+1] given targets[...t], and thus is conditioned on the input sequence.\n",
        "\n",
        "\n",
        "In inference mode, we want to decode unknown input sequences, so we go through a slightly different process:\n",
        "1.  Encode input sequence into state vectors\n",
        "2.  Start with target sequence of size 1 (start of sequence character)\n",
        "3.  Feed state vectors and 1-char target sequence to decoder to produce predictions for the next character\n",
        "4.  Sample next character using these predictions (use simple argmax)\n",
        "5.  Append the sampled character to target sequence\n",
        "6.  Repeat until we generate end of sequence character or hit the character limit -  until we generate [STOP]"
      ],
      "metadata": {
        "id": "6_1EHnxSojuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: `Teacher forcing` is a ML method for training RNN models that use the ground truth from a prior step as the input. [Source](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/)"
      ],
      "metadata": {
        "id": "s4JikhSwro4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras Example <p>\n",
        "Will use a dataset of English-French translation pairs. Will implement character-level seq-2-seq, processing input character-by-character and producing the output in the same manner. <br>\n",
        "Another option is to have a word-level model (tends to be more commend for Machine Translation); can look at in the end of the post..<p>\n",
        "\n",
        "Process Summary:\n",
        "1.  Turn sentences into 3 Numpy arrays: \n",
        "    -  `encoder_input_data`: 3D array of shape `(num_pairs, max_english_sentence_length, num_english_characters)`; containing a one-hot vectorization of the English sentences\n",
        "    -  `decoder_input_data`: 3D array of shape `(num_pairs, max_french_sentence_length, num_french_characters)`; containing one-hot vectorization of the French Sentences\n",
        "    -  `decoder_target_data`: Same as `decoder_input_data`, but offset by one timestep. `decoder_target_data[:, t, :]` will be the same as `decoder_input_data[:, t+1, :]`\n",
        "2.  Train a basic LSTM-based Seq2Seq model to predict `decoder_target_data` given `encoder_input_data` and `decoder_input_data`. Or model uses teacher forcing.\n",
        "3.  Decode some sentences to check that the model is working (i.e. turn samples from `encoder_input_data` into corresponding samples from `decoder_target_data`).\n",
        "<p>\n",
        "\n",
        "Because the training and inference process are different, we use different models for both; albeit they all leverage the same inner layers. <br>\n",
        "Our training model leverages three key features of Keras RNN's:\n",
        "-  `return_state` constructor argument, configuring a RNN layer to return a list where the first entry is the outputs and the next entries are the RNN states. These are used to recovere the states of the encoder.\n",
        "-  The `initial_state` call argument, specifying the initial state(s) of a RNN; this is used to pass the encoder states to the decoder as initial states.\n",
        "-  The `return_sequences` constructor argument, configuring a RNN to return its full sequence of outputs (instead of just the last output, which is the default behaviour). This is used in the decoder."
      ],
      "metadata": {
        "id": "VWPlqwQ-qhA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "ykh0ecUAvY8M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQXTm49Fof6W",
        "outputId": "c5e441e4-f2f1-4374-e8ba-228e66a51727"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  fra-eng.zip',\n",
              " '  inflating: _about.txt              ',\n",
              " '  inflating: fra.txt                 ']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "## Download the file\n",
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
        "!!unzip fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## config\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "# Path to the data txt file on disk.\n",
        "data_path = \"fra.txt\""
      ],
      "metadata": {
        "id": "HZkirIQsxvee"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the data\n",
        "\n",
        "\n",
        "# initialise arrays to store texts and characters\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "# open dataset and read lines\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "# only take up to max num samples or the length of the dataset\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "\n",
        "    # split texts; input, target, info..\n",
        "    input_text, target_text, _ = line.split(\"\\t\") \n",
        "\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "\n",
        "    # append to input and target lists of texts\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    # append characters to input and target text sets\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "# turn sets to list and sort\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "# print some summary stats\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBFTYf0kxS_v",
        "outputId": "e34f9d64-7f5d-4a27-8909-b0390ed7390b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 92\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create indexes of character to index num for input and target\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "print('Number of input tokens', len(input_token_index))\n",
        "print('Number of target tokens', len(target_token_index))\n",
        "\n",
        "# create input and target arrays\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "# decoder target is the same dimensions as decoder input data\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "print(\"Encoder Input data Shape\", encoder_input_data.shape)\n",
        "print('Decoder Input/Target data Shape', decoder_target_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bskTNFAzX66",
        "outputId": "b9529966-e48f-41ec-b3bb-f3c83ae093e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input tokens 71\n",
            "Number of target tokens 92\n",
            "Encoder Input data Shape (10000, 15, 71)\n",
            "Decoder Input/Target data Shape (10000, 59, 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# go through each input text and target text to fill in training inputs\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        \n",
        "    # for input token; set value to 1 in encoder input wherever there is a character.\n",
        "    # also for the space after the input text location; a blank space token\n",
        "    # one-hot representation of the characters that are present for that text\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0 # becomes a very sparse matrix..\n",
        "    # set everything else as having empty space; as no value present for those\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "\n",
        "    # do the same for target data; set 1 wherever there is a character for each text\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        # as encoder wants to predict next timestep; so decoder is just one step ahead..\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            # >> So there is information of one-ahead timestep (what we want to predict)\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0 # shows the character one timestep earlier; no beginning char\n",
        "\n",
        "    # everything else has empty space; no value present for such tokens..\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0 # feeding in t+1; mask all after\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0 # \n"
      ],
      "metadata": {
        "id": "xUAyMvFN0sQj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## build the model\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "# build dense layer with number of output tokens and predict based on decoder outputs\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "Fg1c0Mw4Hkws"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_tWdYBKVMXI",
        "outputId": "9f0b472e-10bd-4ff7-9a8a-9508726aa62f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 71)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 92)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        335872      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  357376      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 92)     23644       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 716,892\n",
            "Trainable params: 716,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "SUclD_sjU7YK",
        "outputId": "e6510077-7f5b-440d-8fae-79cca3dc7fff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train our model\n",
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn8Cobn-Hlec",
        "outputId": "71c36c75-dfb4-43da-e241-0d83dbccb2a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 55s 404ms/step - loss: 1.1353 - accuracy: 0.7365 - val_loss: 1.0524 - val_accuracy: 0.7232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8c06b13510> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8c032cc250> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[decoder_inputs] + decoder_states_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sEYMEximCk0",
        "outputId": "b03bad23-8bc8-477d-9af1-ee6622283529"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, None, 92) dtype=float32 (created by layer 'input_2')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_3')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_4')>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[decoder_outputs] + decoder_states"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K20QP8wKnrlC",
        "outputId": "1dc1abe3-c9c0-49c9-c419-20adb64b589d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, None, 92) dtype=float32 (created by layer 'dense')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mL2zvrOp3Wm",
        "outputId": "56c7539f-74ea-4bba-87a2-7f396194781a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f8c029dea10>,\n",
              " <keras.engine.input_layer.InputLayer at 0x7f8bff2eb450>,\n",
              " <keras.layers.recurrent_v2.LSTM at 0x7f8bfec8a350>,\n",
              " <keras.layers.recurrent_v2.LSTM at 0x7f8bfef02610>,\n",
              " <keras.layers.core.dense.Dense at 0x7f8c02e9e410>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define sampling models\n",
        "\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "# construct encoder\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1 (output of)\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states) #re-build\n",
        "\n",
        "# construct decoder\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # define inputs to our decoder\n",
        "decoder_lstm = model.layers[3] # get lstm\n",
        "# run inputs through lstm\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec] # get decoder states\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# create decoder model; input of \n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, # create [inputs, h, c]\n",
        "    [decoder_outputs] + decoder_states # decoder outputs\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "\n",
        "        # predict output tokens based on current target sequence, and current states value\n",
        "        # states value from encoder model\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c] #update h, c\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "C85pvuOtOKHn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can now generate decoded sequences\n",
        "for seq_index in range(50):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQtajnjuPxPb",
        "outputId": "5f3353b4-8d97-4fab-e62a-e2524a0b241d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Je s e                                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6QYYgVS3QCvU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}