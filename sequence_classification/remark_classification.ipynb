{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cf774-2fda-4bdc-a78b-c4859786fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5d4d8-7c2b-4827-b345-743240614515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all pandas columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a567397-8551-4e50-9137-a45cc3284175",
   "metadata": {},
   "source": [
    "### Open and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045311d5-569f-4cc2-891e-0ba045c2f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_path = './input_ai_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370ceae-be43-4add-9143-b996eaee23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_csv_to_dataframe(input_csv_path: str) -> pd.DataFrame:\n",
    "    # load all lines into list\n",
    "    all_lines = []\n",
    "\n",
    "    with open(input_csv_path, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        for line in tqdm(reader):\n",
    "            all_lines.append(line[:31])\n",
    "\n",
    "    # make into dataframe\n",
    "    df = pd.DataFrame(all_lines)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_input_csv_to_dataframe(input_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d1702-97b7-478e-93bb-4698fedb0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns relevent to remark rating\n",
    "df = df[['Category ID', 'Occurrence Remarks', 'Expert Field Note Rating', 'Expert Remark Rating']]\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3073d-b106-4c9f-b757-59f06fb7562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dd0a9-5d65-4ac8-b94b-92aa05c971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)['Occurrence Remarks'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11542ed-6875-4911-aebb-0d486848df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all occurrence remarks are valid\n",
    "df = df[df['Occurrence Remarks'] != '']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737262b4-1cb5-4216-afd3-a1529fda7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where nan expert field note rating; also where it is 0\n",
    "df = df[df['Expert Field Note Rating'] != '']\n",
    "df = df[df['Expert Field Note Rating'] != '0.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7f292-ee6e-4851-bf2f-2890e9973114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Expert Field Note Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d35dcf-1e72-4614-88af-c72feffbf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# really not that many data points to go off of..\n",
    "sns.countplot(x='Expert Field Note Rating', data=df)\n",
    "plt.title('Expert Field Note Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50e93e-2c36-4f59-ac37-9b63fec35933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# really not that many data points to go off of..\n",
    "sns.countplot(x='Expert Remark Rating', data=df)\n",
    "plt.title('Expert Remark Rating Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661b382-c6c6-4c61-b462-b77b4c558115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99dfcb-1f90-4a30-9387-33ea208c23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn expert remark rating into an int\n",
    "df['Expert Field Note Rating'] = df['Expert Field Note Rating'].apply(lambda x: int(float(x)))\n",
    "df['Expert Remark Rating'] = df['Expert Remark Rating'].apply(lambda x: int(float(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1fbd7-b004-4e4f-bb9d-ff0500e5e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# field note rating must start from 0\n",
    "# df['Expert Field Note Rating'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489794dc-bc75-485f-9fe1-8a87826ea57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664ca0a-4a69-40d8-b12a-b58b1e23233f",
   "metadata": {},
   "source": [
    "### Preprocess text\n",
    "https://machinelearningknowledge.ai/11-techniques-of-text-preprocessing-using-nltk-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa2c25-6f48-48b2-aeec-bf6c567cf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336abd85-e448-44ec-b66f-f933bea484a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376fef8-e545-410e-bb5a-d954b7d2e176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    result = [token for token in text if token not in en_stopwords]\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_tag(text):\n",
    "    text=' '.join(text)\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39c7aa-b2c0-4c90-bd0f-2b2fd511bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "print('Removing Whitespace')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(remove_whitespace)\n",
    "\n",
    "print('Tokenizing words')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(word_tokenize) \n",
    "\n",
    "print('Removing stopwords')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(lambda x: remove_stopwords(x)) \n",
    "\n",
    "print('Removing punctuation')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(lambda x: \" \".join(remove_punct(x)))\n",
    "\n",
    "print('Removing URLs')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(remove_urls) \n",
    "\n",
    "print('Lemmatizing')\n",
    "df['Occurrence Remarks'] = df['Occurrence Remarks'].progress_apply(lambda x: \" \".join(lemmatization(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c33a3-4418-4fa3-a684-51db2e0d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e7fc01-c677-4d11-8a8e-16d8fe76fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('Occurrence Remarks', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf03241-1eba-4cee-b066-eaf9da8a7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include category, see if it makes a difference.\n",
    "df['Occurrence Remarks'] = df.apply(lambda x: f\"category id {x['Category ID']}. {x['Occurrence Remarks']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6e6c5-ca48-47f9-a72d-e1d8fd8bf2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fc59c-4dd7-4cce-85c0-bf11ff373f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./remarks_data.pickle') # save as picklefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255c7e8-b119-4f79-aefb-3c1863282bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save text file\n",
    "with open('./remarks.txt', 'w+') as wf:\n",
    "    for el, jun in df[['Expert Field Note Rating', 'Occurrence Remarks']].values:\n",
    "        string = f\"__label__{el} {jun}\"\n",
    "        wf.write(string)\n",
    "        wf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9b060-b292-4298-ad7a-60a0f73e54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for total of 10000 data points\n",
    "!head -n 1200 remarks.txt > remarks.train\n",
    "!tail -n 262 remarks.txt > remarks.valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0327ca-b4ce-4e3d-8ac0-a4fd3bd30bfb",
   "metadata": {},
   "source": [
    "### Train Using FastText\n",
    "https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a7814-a336-4138-bb3c-bbf017cf0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b0c9f-ab62-49e8-96b5-f3aea8faf847",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"remarks.train\", lr=1, epoch=100, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015eef4-787e-4ef9-a896-01dc3d538e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_model(\"model_remarks.bin\") #load_model does the inverse\n",
    "\n",
    "# model.test(\"remarks.valid\") # precision, recall at 1; how often highest ranked document contains correct answer\n",
    "model.test(\"remarks.valid\", k=5) # precision, recall at 5. want > 0.2 precision, otherwise no better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6291f3-38f2-4ca2-bc41-621bc85b1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict simply reflects the distribution of the data; almost guessing here..\n",
    "model.predict(\"category level 23. what an amazing kangaroo\", k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dde389-8449-49f2-a7b6-02204147a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"remarks.valid\", k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7981d13-6d54-4ed8-a653-d8c471821cb5",
   "metadata": {},
   "source": [
    "### Results are not that great; let's try BERT\n",
    "-  MultiLabel Classification: https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb#scrollTo=0DF3ddjej5vd\n",
    "-  MultiClass Classification: https://github.com/susanli2016/NLP-with-Python/blob/master/Text_Classification_With_BERT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1c210-eacd-482d-b31b-49993bded6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8deb87-1fe3-49da-a24c-30742cae83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Expert Field Note Rating'] -= 1 # make 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9294f7-5a95-404a-9661-ec0d52ee82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(df['Expert Field Note Rating'].unique())\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d200af-24e6-435c-9f43-18d065327342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df['Expert Field Note Rating'].values, \n",
    "                                                  test_size=0.10, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df['Expert Field Note Rating'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb0a49-eb79-4ca9-9622-e6dcab42b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bc98b-aa0d-4d2c-bc03-19ec834003c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Expert Field Note Rating', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4e39e-818a-4084-a278-6447531dca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[df.data_type=='train']['Occurrence Remarks'].values\n",
    "X_val = df[df.data_type=='val']['Occurrence Remarks'].values\n",
    "y_train = df[df.data_type=='train']['Expert Field Note Rating'].values\n",
    "y_val = df[df.data_type=='val']['Expert Field Note Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9b95b-78d4-4682-bbe1-0c9ce35e3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try under-sampling, see if this improves our results (we have a lot less data as a result)\n",
    "from imblearn.under_sampling  import RandomUnderSampler\n",
    "\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = under_sampler.fit_resample(X_train.reshape(-1,1), y_train.reshape(-1,1))\n",
    "print(X_res.shape, y_res.shape)\n",
    "X_train=X_res.reshape(-1)\n",
    "y_train=y_res.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea0f5a-d7d0-4c3d-8e86-72d57cd7a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7814829-f12e-4577-a330-bc6e92a676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fc7ba-99ed-4347-bce5-df4d0a7819f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    X_train, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=256, # tested 512 here, doesn't make much of a difference\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    X_val, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=256, # can go up to 512 but we run into some memory issues..\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce82fd-359a-4fc2-8460-cd9007459296",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9be7c-b076-4f30-8b23-f4b37be99399",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d280-720c-4ba8-80f4-91f579fb1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889530c-60ce-4ca3-80a4-d7e4dde939c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16 \n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a855a-6b2c-4035-a960-c61e82500770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28374a69-2083-48fa-a4f3-cbed7ff81983",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719f8f6-c114-4970-a1e5-f7f31a81a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Expert Field Note Rating'].unique() # can try to predict results as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7999c-8ab1-4b85-b184-65cc886cb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74a055-887d-458c-ba41-13d53afd6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e31055-2236-40e8-bcca-fee72a9751b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# see what gpus are available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e40b3-987b-4898-b3bc-ad554c459046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e9c7b-e9bc-48a5-b694-023b51f93e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66a871-3982-4994-bfb3-c50caeb46bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ab4bc-a955-458d-a4f1-0af9eb0c390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/finetuned_BERT_epoch_4.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4174d-22b6-4f23-b73c-e2eb55518564",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "flattened_predictions = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e682b-d716-4e51-a2e6-60b47fe59bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([X_val, flattened_predictions]).T.to_csv('output_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b3d00-d3ad-4333-ab88-c9c1c739608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701281aa-9444-41d7-a4dc-5e6d4f3af0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "print(sklearn.metrics.classification_report(true_vals, flattened_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab310d46-2b5c-4d12-9a02-5b3c6a0d9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427aff8a-615d-4f04-b28c-2017f42075d1",
   "metadata": {},
   "source": [
    "### Load and Make Predictions on Sample String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabcda5-c981-4bf3-979c-05f27c41508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2046f8-e740-400b-9739-c32458281c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    result = [token for token in text if token not in en_stopwords]\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_tag(text):\n",
    "    text=' '.join(text)\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def preprocess_input_text(text):\n",
    "    text = remove_whitespace(text)\n",
    "    text = word_tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_punct(text)\n",
    "    text = lemmatization(text)\n",
    "    text = \" \".join(text)\n",
    "    text = remove_urls(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d2fd6-158f-410e-a85f-dbddb1a51822",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_STRING = \"\"\"category level 23. how must  i get level 1, this cannot be happening\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_labels = 5\n",
    "\n",
    "# load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/finetuned_BERT_epoch_5.model', map_location=torch.device('cpu')))\n",
    "\n",
    "# preprocess\n",
    "processed_sample_string = [preprocess_input_text(SAMPLE_STRING)]\n",
    "\n",
    "# tokenize\n",
    "encoded_string = tokenizer.batch_encode_plus(\n",
    "    processed_sample_string, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=512, # can go up to 512 but we run into some memory issues..\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# separate to input ids, attention mask and labels\n",
    "input_ids_sample = encoded_string['input_ids']\n",
    "attention_masks_sample = encoded_string['attention_mask']\n",
    "labels_sample = torch.tensor(np.ones(len(processed_sample_string))).type(torch.LongTensor)\n",
    "\n",
    "# create tensor dataset\n",
    "dataset_sample = TensorDataset(input_ids_sample, attention_masks_sample, labels_sample)\n",
    "dataloader_sample = DataLoader(dataset_sample, sampler=SequentialSampler(dataset_sample), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fefa1-e206-400c-b601-e98c7ee165e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fccab-a26c-43b8-b8c5-a3ccaafa521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7f483-c860-4ca8-987e-b1538d2d6afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
