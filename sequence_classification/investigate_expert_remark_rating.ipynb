{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17cf774-2fda-4bdc-a78b-c4859786fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5d4d8-7c2b-4827-b345-743240614515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all pandas columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a567397-8551-4e50-9137-a45cc3284175",
   "metadata": {},
   "source": [
    "### Open and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045311d5-569f-4cc2-891e-0ba045c2f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_path = './input_ai_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370ceae-be43-4add-9143-b996eaee23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_csv_to_dataframe(input_csv_path: str) -> pd.DataFrame:\n",
    "    # load all lines into list\n",
    "    all_lines = []\n",
    "\n",
    "    with open(input_csv_path, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        for line in tqdm(reader):\n",
    "            all_lines.append(line[:31])\n",
    "\n",
    "    # make into dataframe\n",
    "    df = pd.DataFrame(all_lines)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = load_input_csv_to_dataframe(input_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d1702-97b7-478e-93bb-4698fedb0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns relevent to remark rating\n",
    "df = df[['Category ID', 'Player Level', 'User Note', 'Occurrence Remarks', 'Expert Remark Rating', 'Expert Level', 'Expert Field Note Rating']]\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b496d-c0ef-4a8b-8d56-f1165070f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all before taxon tree (what was added post processing)\n",
    "df['User Note'] = df['User Note'].apply(lambda x: x.split('Taxon Tree')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3073d-b106-4c9f-b757-59f06fb7562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dd0a9-5d65-4ac8-b94b-92aa05c971d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)['Occurrence Remarks'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11542ed-6875-4911-aebb-0d486848df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all occurrence remarks are valid\n",
    "df = df[df['Occurrence Remarks'] != '']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737262b4-1cb5-4216-afd3-a1529fda7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where nan expert remark rating\n",
    "df = df[df['Expert Remark Rating'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d35dcf-1e72-4614-88af-c72feffbf7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Expert Remark Rating', data=df)\n",
    "plt.title('Expert Remark Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661b382-c6c6-4c61-b462-b77b4c558115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99dfcb-1f90-4a30-9387-33ea208c23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn expert remark rating into an int\n",
    "df['Expert Remark Rating'] = df['Expert Remark Rating'].apply(lambda x: int(float(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489794dc-bc75-485f-9fe1-8a87826ea57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664ca0a-4a69-40d8-b12a-b58b1e23233f",
   "metadata": {},
   "source": [
    "### Preprocess text\n",
    "https://machinelearningknowledge.ai/11-techniques-of-text-preprocessing-using-nltk-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa2c25-6f48-48b2-aeec-bf6c567cf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336abd85-e448-44ec-b66f-f933bea484a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376fef8-e545-410e-bb5a-d954b7d2e176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    result = [token for token in text if token not in en_stopwords]\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_tag(text):\n",
    "    text=' '.join(text)\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290ba42-cf11-4ccc-9de6-74293e892010",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df#sample(10_000).copy() # take subset of 10000 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39c7aa-b2c0-4c90-bd0f-2b2fd511bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "print('Removing Whitespace')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(remove_whitespace)\n",
    "\n",
    "print('Tokenizing words')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(word_tokenize) \n",
    "\n",
    "print('Removing stopwords')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(lambda x: remove_stopwords(x)) \n",
    "\n",
    "print('Removing punctuation')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(lambda x: \" \".join(remove_punct(x)))\n",
    "\n",
    "print('Removing URLs')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(remove_urls) \n",
    "\n",
    "print('Lemmatizing')\n",
    "subset_df['Occurrence Remarks'] = subset_df['Occurrence Remarks'].progress_apply(lambda x: \" \".join(lemmatization(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf03241-1eba-4cee-b066-eaf9da8a7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include player encoding into string; of category and level, see if it makes a difference.\n",
    "df['Occurrence Remarks'] = df.apply(lambda x: f\"player level {x['Player Level']}. category level {x['Category ID']}. {x['Occurrence Remarks']}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255c7e8-b119-4f79-aefb-3c1863282bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save text file\n",
    "with open('./remarks.txt', 'w+') as wf:\n",
    "    for el, jun in subset_df[['Expert Remark Rating', 'Occurrence Remarks']].values:\n",
    "        string = f\"__label__{el} {jun}\"\n",
    "        wf.write(string)\n",
    "        wf.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9b060-b292-4298-ad7a-60a0f73e54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for total of 10000 data points\n",
    "!head -n 300000 remarks.txt > remarks.train\n",
    "!tail -n 11918 remarks.txt > remarks.valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0327ca-b4ce-4e3d-8ac0-a4fd3bd30bfb",
   "metadata": {},
   "source": [
    "### Train Using FastText\n",
    "https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a7814-a336-4138-bb3c-bbf017cf0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b0c9f-ab62-49e8-96b5-f3aea8faf847",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"remarks.train\", lr=1, epoch=100, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015eef4-787e-4ef9-a896-01dc3d538e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_model(\"model_remarks.bin\") #load_model does the inverse\n",
    "\n",
    "# model.test(\"remarks.valid\") # precision, recall at 1; how often highest ranked document contains correct answer\n",
    "model.test(\"remarks.valid\", k=5) # precision, recall at 5. want > 0.2 precision, otherwise no better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6291f3-38f2-4ca2-bc41-621bc85b1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"player level 10. category level 23. what an amazing kangaroo\", k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dde389-8449-49f2-a7b6-02204147a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"remarks.valid\", k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7981d13-6d54-4ed8-a653-d8c471821cb5",
   "metadata": {},
   "source": [
    "### Results are not that great; let's try BERT\n",
    "-  MultiLabel Classification: https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb#scrollTo=0DF3ddjej5vd\n",
    "-  MultiClass Classification: https://github.com/susanli2016/NLP-with-Python/blob/master/Text_Classification_With_BERT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1c210-eacd-482d-b31b-49993bded6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9294f7-5a95-404a-9661-ec0d52ee82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(subset_df['Expert Remark Rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d200af-24e6-435c-9f43-18d065327342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(subset_df.index.values, \n",
    "                                                  subset_df['Expert Remark Rating'].values, \n",
    "                                                  test_size=0.10, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=subset_df['Expert Remark Rating'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb0a49-eb79-4ca9-9622-e6dcab42b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df['data_type'] = ['not_set']*subset_df.shape[0]\n",
    "\n",
    "subset_df.loc[X_train, 'data_type'] = 'train'\n",
    "subset_df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bc98b-aa0d-4d2c-bc03-19ec834003c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.groupby(['Expert Remark Rating', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7814829-f12e-4577-a330-bc6e92a676e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fc7ba-99ed-4347-bce5-df4d0a7819f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    subset_df[subset_df.data_type=='train']['Occurrence Remarks'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=256, # tested 512 here, doesn't make much of a difference\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    subset_df[subset_df.data_type=='val']['Occurrence Remarks'].values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=256, # can go up to 512 but we run into some memory issues..\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(subset_df[subset_df.data_type=='train']['Expert Remark Rating'].values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(subset_df[subset_df.data_type=='val']['Expert Remark Rating'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce82fd-359a-4fc2-8460-cd9007459296",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9be7c-b076-4f30-8b23-f4b37be99399",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8d280-720c-4ba8-80f4-91f579fb1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889530c-60ce-4ca3-80a4-d7e4dde939c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16 \n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a855a-6b2c-4035-a960-c61e82500770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28374a69-2083-48fa-a4f3-cbed7ff81983",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719f8f6-c114-4970-a1e5-f7f31a81a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df['Expert Remark Rating'].unique() # can try to predict results as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7999c-8ab1-4b85-b184-65cc886cb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74a055-887d-458c-ba41-13d53afd6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e31055-2236-40e8-bcca-fee72a9751b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# see what gpus are available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e40b3-987b-4898-b3bc-ad554c459046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e9c7b-e9bc-48a5-b694-023b51f93e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'models/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))\n",
    "HBox(children=(FloatProgress(value=0.0, description='Epoch ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66a871-3982-4994-bfb3-c50caeb46bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ab4bc-a955-458d-a4f1-0af9eb0c390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/finetuned_BERT_epoch_5.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4174d-22b6-4f23-b73c-e2eb55518564",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "flattened_predictions = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701281aa-9444-41d7-a4dc-5e6d4f3af0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "print(sklearn.metrics.classification_report(true_vals, flattened_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab310d46-2b5c-4d12-9a02-5b3c6a0d9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427aff8a-615d-4f04-b28c-2017f42075d1",
   "metadata": {},
   "source": [
    "### Load and Make Predictions on Sample String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabcda5-c981-4bf3-979c-05f27c41508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2046f8-e740-400b-9739-c32458281c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    result = [token for token in text if token not in en_stopwords]\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_tag(text):\n",
    "    text=' '.join(text)\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def preprocess_input_text(text):\n",
    "    text = remove_whitespace(text)\n",
    "    text = word_tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_punct(text)\n",
    "    text = lemmatization(text)\n",
    "    text = \" \".join(text)\n",
    "    text = remove_urls(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d2fd6-158f-410e-a85f-dbddb1a51822",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_STRING = \"\"\"\n",
    "A good sighting of the Superb Fairywren (Malurus cyaneus). \n",
    "\n",
    "-------------\n",
    "Adult male Superb Fairy-wrens are among the most brightly coloured of the species, especially during the breeding season. They have rich blue and black plumage above and on the throat. The belly is grey-white and the bill is black. Females and young birds are mostly brown above with a dull red-orange area around the eye and a brown bill. Females have a pale greenish gloss, absent in young birds, on the otherwise brown tail. The legs are brown in both sexes. Males from further inland and in the south-west of the range have more blue on the back and underparts.\n",
    "\n",
    "Similar species: \n",
    "Several other species of fairy-wren are found in Australia. The males of each species are quite distinct, but the females and young birds are often difficult to separate. Of the species that overlap in range with the Superb Fairy-wren, the female White-winged Fairy-wren Malurus leucopterus and Red-backed Fairy-wren M. melanocephalus lacks the chestnut colour around the eye, while the female Variegated Fairy-wren M. lamberti has a dull grey-blue wash. Both the Superb and White-winged Fairy-wrens are similar in size. The Variegated Fairy-wren is slightly larger in size and has a longer tail.\n",
    "\n",
    "Where does it live?\n",
    "Distribution: \n",
    "Superb Fairy-wrens are found south of the Tropic of Capricorn through eastern Australia and Tasmania to the south-eastern corner of South Australia.\n",
    "\n",
    "Habitat: \n",
    "Seen in most habitat types where suitable dense cover and low shrubs occur. They are common in urban parks and gardens, and can be seen in small social groups. These groups normally consist of one dominant male and several females and young birds.\n",
    "\n",
    "What does it do?\n",
    "Feeding: \n",
    "Superb Fairy-wrens feed on insects and other small arthropods. These are caught mostly on the ground, but may also be taken from low bushes. Feeding takes place in small social groups.\n",
    "\n",
    "Breeding: \n",
    "The nest is a dome-shaped structure of grasses and other fine material. It is usually placed in a low bush and is constructed by the female. The female incubates the eggs alone, but both sexes feed the young. Other members of the group will also help with the feeding of the young.\n",
    "\n",
    "References: \n",
    "Field Guide to the Birds of Australia.\n",
    "Handbook of Australian, New Zealand and Antarctic Birds, Volume 5 {(Tyrant-flycatchers} to Chats).\n",
    "Reader's Digest Complete Book of Australian Birds\n",
    "The Wrens and Warblers of Australia\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_labels = 6\n",
    "\n",
    "# load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=num_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/finetuned_BERT_epoch_5.model', map_location=torch.device('cpu')))\n",
    "\n",
    "# preprocess\n",
    "processed_sample_string = [preprocess_input_text(SAMPLE_STRING)]\n",
    "\n",
    "# tokenize\n",
    "encoded_string = tokenizer.batch_encode_plus(\n",
    "    processed_sample_string, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=True, \n",
    "    max_length=512, # can go up to 512 but we run into some memory issues..\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# separate to input ids, attention mask and labels\n",
    "input_ids_sample = encoded_string['input_ids']\n",
    "attention_masks_sample = encoded_string['attention_mask']\n",
    "labels_sample = torch.tensor(np.ones(len(processed_sample_string))).type(torch.LongTensor)\n",
    "\n",
    "# create tensor dataset\n",
    "dataset_sample = TensorDataset(input_ids_sample, attention_masks_sample, labels_sample)\n",
    "dataloader_sample = DataLoader(dataset_sample, sampler=SequentialSampler(dataset_sample), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fefa1-e206-400c-b601-e98c7ee165e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fccab-a26c-43b8-b8c5-a3ccaafa521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7f483-c860-4ca8-987e-b1538d2d6afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
